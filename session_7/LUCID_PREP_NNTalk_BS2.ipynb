{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LUCID_PREP_NNTalk_BS2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMF57QM2jiYv",
        "colab_type": "text"
      },
      "source": [
        "# Session 7: Neural Networks #\n",
        "\n",
        "Machine learning and artificial intelligence technology is growing at an impressive rate. From robotics and self-driving cars to augmented reality devices and facial recognition software, models that make predictions from data are all around us. Many of these applications implement neural networks, which basically allows the computer to analyze data similar to the way the human brain analyzes data.\n",
        "\n",
        "With recent advancements in computing power and the explosion of big data, we can now implement large models that perform end-to-end learning (deep learning). This means that we can create a model, feed it tons and tons of data, and the model will learn features from the data that are important for accomplishing the task.\n",
        "\n",
        "Session outline:\n",
        "* Introduce the simplest neural network, the perceptron\n",
        "* Discuss the general architecture for neural networks\n",
        "* Implement a neural network to solve a hand writing recognition task\n",
        "* Introduce deep learning (convolutional neural networks)\n",
        "* Implement a deep neural network to solve a hand writing recognition task\n",
        "\n",
        "#### Preparation for the workshop: ####\n",
        "\n",
        "1. Watch the following videos:\n",
        "* https://www.youtube.com/watch?v=aircAruvnKk\n",
        "* https://www.youtube.com/watch?v=uXt8qF2Zzfo&t=1973s (Watch first 12 min)\n",
        "* https://www.youtube.com/watch?v=YRhxdVk_sIs\n",
        "\n",
        "2. Pull session 7 materials from GitHub\n",
        "* https://github.com/pabloinsente/LUCID_data_workshop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Tf2c2hkKST",
        "colab_type": "text"
      },
      "source": [
        "## Breakout Session #2: Convolutional Neural Networks ##\n",
        "\n",
        "The following code has been modified from:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "**_Please visit the website to see the original code and explaination._\n",
        "\n",
        "#### Instructions: ####\n",
        "\n",
        "Read through the explaination for each section of cade and then run each block of code in consecutive order. If you have any questions about the code or the underlying theory please raise your hand and ask (_if you have questions after the session, please send me an email at doudlah@wisc.edu_).\n",
        "\n",
        "\\\n",
        "\n",
        "For this session, we will use **Pytorch**, another open source deep learning library. To learn more, visit the Pytorch website (https://pytorch.org/). There are many great tutorials to check out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JSEr1tcrAs5",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Preparing the data ##\n",
        "\n",
        "_**Note:** The MNIST dataset is freely available (http://yann.lecun.com/exdb/mnist/). Feel free to visit the website to learn more about the dataset and how it was created._\n",
        "\n",
        "Pytorch also has a built-in fuction for downloading the MNIST dataset. We will load a training dataset and a test dataset. We also display some example images from the MNIST dataset. Do you notice any similarities to breakout session #1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVW30ewkQjR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Transform torchvision dataset from [0,1] to [-1,1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load training data\n",
        "trainData = torchvision.datasets.MNIST(root='./CNN_Data',train=True,\n",
        "                                      download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainData, batch_size=10,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Load testing data\n",
        "testData = torchvision.datasets.MNIST(root='./CNN_Data',train=False,\n",
        "                                      download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testData, batch_size=10,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('Digit_0','Digit_1','Digit_2','Digit_3','Digit_4','Digit_5',\n",
        "           'Digit_6','Digit_7','Digit_8','Digit_9')\n",
        "\n",
        "# Display example images\n",
        "dataiter = iter(trainloader)\n",
        "images,labels = dataiter.next()\n",
        "\n",
        "# Display example hand written digits\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(9):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(images[i].squeeze(), cmap=plt.cm.binary)\n",
        "  plt.title(classes[labels[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu2SuJu5yNkz",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Building the Convolutional Neural Network Model ##\n",
        "\n",
        "To build the model, we define a class and add all of the layers and computational steps. Here we have three fully connected layers with 120, 84, and 10 nodes in each respective layer. Notice how the last layer must still have 10 nodes becasue we are differentiating between 10 classes. \n",
        "\n",
        "The \"forward\" function takes the input image $x$ and propagates the data through the network. Notice that after each convolution we apply the \"relu\" activation function and then pool (or downsample) the data. \n",
        "\n",
        "Feel free to modify the number of layers and the number of nodes in each layer. Remember that the time it will take to train the network is directly proportional to the number of layers and the number of nodes in each layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DtcZbnFXZ56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 4)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 4)\n",
        "    self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 4 * 4)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "net = Net()\n",
        "\n",
        "# Define a loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzXyue2W6x1k",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Train the network ##\n",
        "\n",
        "Here, we will train the neural network and print the accuracy at the end of training. Feel free to play with the number of epochs, or times the model will train on all of the images but be careful of overfitting. \n",
        "\n",
        "There is a lot that goes into training a model. You need to send some images through your model, calculate a loss from the true labels, and then update all of the weights in the network.\n",
        "\n",
        "_**Note:** This make take a few minutes to run because it is processing 60,000 images. The number of epochs is directly related to the time that it will take the model to run._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2W1-d1-ZC2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the number of times you want to loop over the dataset\n",
        "numEpochs = 2\n",
        "\n",
        "# Train the network\n",
        "for epoch in range(numEpochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # Get the image and the corresponding label\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # Zero the gradients of the parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Run data through the network, calculate the loss and update weights\n",
        "    outputs = net(inputs)\n",
        "#     print('Inputs:',inputs.shape)\n",
        "#     print('Outputs:',outputs.shape)\n",
        "#     print('Labels:',labels.shape)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Print statistics every 2000 epochs\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print('[%d, %5d] loss: %0.3f' % \n",
        "           (epoch + 1, i + 1, running_loss/2000))\n",
        "      \n",
        "print('Finished Training!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeWV__RD8J-a",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Test the network ##\n",
        "\n",
        "As with any kind of machine learning, it is always important to test the network on data that it did not see in training. Here, we use our \"testing\" dataset to check the actual accuracy of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMvjeYYgoCsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3qMDVx600hS",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Check your results ##\n",
        "\n",
        "By just using a convolutional neural network with only a few fully connected layers we can get a pretty high accuracy. It is always advisable to check your output of your model to verify that it is working as expected. \n",
        "\n",
        "We can also check the accuracy of each class that was tested? Did any class have a lower accuracy than the rest?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnbf1LkJoTu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create list to hold accuracy of each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for j, data in enumerate(testloader, 0):\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    # Update accuracy for each class\n",
        "    for i in range(10):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}